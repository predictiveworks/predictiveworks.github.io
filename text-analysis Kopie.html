<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Text Analysis</title>
    <link rel="stylesheet" href="/assets/css/fontawesome-free-5.10.1-web/css/all.min.css"/>
    <link rel="stylesheet" href="/assets/css/styles.css">
  </head>
  <body>
    <div class="site-wrapper">

      
<div class="site-header">

  <!-- title -->
  <div class="site-header-title">
    <div class="column-left"></div>
    <div class="column-content">
      <div class="header-content">
        <div class="logo"></div>
        <div class="header-title">
          <span class="brand-grey">Predictive</span><span class="brand-teal">Works.</span>
        </div>
      </div>
    </div>
    <div class="column-right"></div>
  </div>

  <!-- breadcrumbs -->
  <div class="site-header-breadcrumbs">
    <div class="column-left"></div>
    <div class="column-content">
      
        <ul class="breadcrumb">
          <li><a href="/">PredictiveWorks</a> </li>
          
          
            <li class="active">
              
              <i class="fa fa-chevron-right fa-icon"></i>
              text analysis%20Kopie
              
            </li>
          
        </ul>
      
    </div>
    <div class="column-right"></div>
  </div>

</div>


      <div class="site-content">
        <div class="column-left"></div>
        <div class="column-content">
          <div class="main-content">
            <div class="main-content-nav">
              <nav class="nav-main">
  <div class="nav-container">
    <!-- concepts -->
    <div class="nav-title">Basic Concepts</div>

      <a href="/what-is-predictiveworks.html">
        <div class="nav-article">What is PredictiveWorks?</div>
      </a>

      <a href="/technology-stack.html">
        <div class="nav-article">Technology Stack</div>
      </a>

      <a href="/visual-analytics.html">
        <div class="nav-article">Visual Analytics</div>
      </a>

      <a href="/maturity-model.html">
        <div class="nav-article">Maturity Model</div>
      </a>

      <a href="/what-others-do.html">
        <div class="nav-article">What Others Do</div>
      </a>

    <!-- connectors -->
    <div class="nav-title">Data Connectors</div>

      <a href="/built-in-connectors.html">
        <div class="nav-article">Built-in Connectors</div>
      </a>

      <a href="/purpose-built-connectors.html">
        <div class="nav-article">Purpose-built Connectors</div>
      </a>

    <!-- rules & queries -->
    <div class="nav-title">Rules & Queries</div>

      <a href="/drools-rules.html">
        <div class="nav-article">Drools Rules</div>
      </a>

      <a href="/spark-sql.html">
        <div class="nav-article">Spark SQL</div>
      </a>

    <!-- machine learning -->
    <div class="nav-title">Machine Learning</div>

      <a href="/machine-learning.html">
        <div class="nav-article">Machine Learning</div>
      </a>

      <a href="/feature-engineering.html">
        <div class="nav-article">Feature Engineering</div>
      </a>

      <a href="/anomaly-detection.html">
        <div class="nav-article">Anomaly Detection</div>
      </a>

      <a href="/classification.html">
        <div class="nav-article">Classification</div>
      </a>

      <a href="/clustering.html">
        <div class="nav-article">Clustering</div>
      </a>

      <a href="/data-mining.html">
        <div class="nav-article">Data Mining</div>
      </a>

      <a href="/predictions.html">
        <div class="nav-article">Prediction</div>
      </a>

      <a href="/recommendations.html">
        <div class="nav-article">Recommendation</div>
      </a>

      <a href="/regressions.html">
        <div class="nav-article">Regression</div>
      </a>

      <a href="/smote-sampling.html">
        <div class="nav-article">SMOTE Sampling</div>
      </a>

    <!-- deep learning -->
    <div class="nav-title">Deep Learning</div>

      <a href="/deep-learning.html">
        <div class="nav-article">Deep Learning</div>
      </a>

    <!-- timeseries -->
    <div class="nav-title">Time Series</div>

      <a href="/time-series-analysis.html">
        <div class="nav-article">Time Series Analysis</div>
      </a>

      <a href="/time-preprocessing.html">
        <div class="nav-article">Preprocessing</div>
      </a>

      <a href="/arima.html">
        <div class="nav-article">ARIMA</div>
      </a>

      <a href="/arma.html">
        <div class="nav-article">ARMA</div>
      </a>

      <a href="/autoregression.html">
        <div class="nav-article">Auto Regression</div>
      </a>

      <a href="/demand-prediction.html">
        <div class="nav-article">Demand Prediction</div>
      </a>

      <a href="/moving-average.html">
        <div class="nav-article">Moving Average</div>
      </a>

      <a href="/stl-decomposition.html">
        <div class="nav-article">STL Decomposition</div>
      </a>

      <a href="/time-regression.html">
        <div class="nav-article">Time Regression</div>
      </a>

    <!-- natural language processing -->
    <div class="nav-title">Natural Language Processing</div>

      <a href="/text-analysis.html">
        <div class="nav-article">Text Analysis</div>
      </a>

      <a href="/text-preprocessing.html">
        <div class="nav-article">Preprocessing</div>
      </a>

      <a href="/text-chunking.html">
        <div class="nav-article">Chunking</div>
      </a>

      <a href="/dependency-parsing.html">
        <div class="nav-article">Dependency Parsing</div>
      </a>

      <a href="/text-embeddings.html">
        <div class="nav-article">Embeddings</div>
      </a>

      <a href="/text-lemmatization.html">
        <div class="nav-article">Lemmatization</div>
      </a>

      <a href="/named-entity-recognition.html">
        <div class="nav-article">Named Entity Recognition</div>
      </a>

      <a href="/part-of-speech-tagging.html">
        <div class="nav-article">Part of Speech Tagging</div>
      </a>

      <a href="/sentiment-analysis.html">
        <div class="nav-article">Sentiment Analysis</div>
      </a>

      <a href="/spell-checking.html">
        <div class="nav-article">Spell Checking</div>
      </a>

      <a href="/text-clustering.html">
        <div class="nav-article">Text Clustering</div>
      </a>

      <a href="/text-matching.html">
        <div class="nav-article">Text Matching</div>
      </a>

      <a href="/topic-modeling.html">
        <div class="nav-article">Topic Modeling</div>
      </a>

    <!-- model management -->
    <div class="nav-title">Model Management</div>

      <a href="/model-management.html">
        <div class="nav-article">Model Management</div>
      </a>

    <!-- model visualization -->
    <div class="nav-title">Model Visualization</div>

      <a href="/grafana-connector.html">
        <div class="nav-article">Grafana Connector</div>
      </a>

    <!-- pipeline operation -->
    <div class="nav-title">Pipeline Operation</div>

      <a href="/template-studio.html">
        <div class="nav-article">Template Studio</div>
      </a>

      <a href="/foresight-fabric.html">
        <div class="nav-article">Foresight Fabric</div>
      </a>

    <!-- pipeline knowledge -->
    <div class="nav-title">Pipeline Knowledge</div>

      <a href="/business-templates.html">
        <div class="nav-article">Business Templates</div>
      </a>

      <a href="/template-market.html">
        <div class="nav-article">Template Market</div>
      </a>

    <!-- graph processing -->
    <div class="nav-title">Graph Processing</div>

      <a href="/janusgraph-ignite.html">
        <div class="nav-article">JanusGraph meets Ignite</div>
      </a>

      <a href="/graph-ingestion.html">
        <div class="nav-article">Graph Ingestion</div>
      </a>

  </div>
</nav>

            </div>
            <div class="main-content-body">
              <h1 id="overview-text-analysis">Overview: Text Analysis</h1>

<h2 id="why-text-analysis">Why Text Analysis?</h2>

<blockquote>
<p>
According to reliable industry estimates, less than 25% of the available data is present in structured form. Data is being generated as we speak, tweet, send messages and in various other activities. The majority exists in the textual form, which is highly unstructured in nature.
</p>
</blockquote>

<p>Information present in unstructured text is not directly accessible unless it is processed. Natural Language Processing (NLP) is an instrument to produce significant and actionable insights from text.</p>

<p>What “text” means, is a matter of context and imagination and is not restricted to news articles, social media posts or user product reviews. For example, in cyber security, NLP can be used to tackle the following problems:</p>

<ul>
  <li>
    <p>Domain Generation Algorithm (DGA) classification: Identification of malicious domains (blbwpvcyztrepfue.ru)</p>
  </li>
  <li>
    <p>Source Code Vulnerability Analysis: Determining function patterns associated with known vulnerabilities to identify other potentially vulnerable code segments.</p>
  </li>
  <li>
    <p>Phishing Identification: A bag of words model determines the probability an email message contains a phishing attempt or not.</p>
  </li>
  <li>
    <p>Malware Family Analysis: Topic modeling assigns samples of malware to “their” families.</p>
  </li>
</ul>

<h2 id="important-tasks">Important Tasks</h2>

<h3 id="text-classification">Text Classification</h3>

<p>This is one of the classical use cases of text analysis. Examples include</p>

<ul>
  <li>
    <p>Email Spam Identification</p>
  </li>
  <li>
    <p>Topic classification of news</p>
  </li>
  <li>
    <p>Sentiment classification and organization of web pages by search engines.</p>
  </li>
</ul>

<p>Text classification, in common words is defined as a technique to systematically classify a text object (document or sentence) in one of the fixed category. It is really helpful when the amount of data is too large, especially for organizing, information filtering, and storage purposes.</p>

<p>A typical natural language classifier consists of two parts: (a) Training (b) Prediction as shown in image below. Firstly the text input is processes and features are created. The machine learning models then learn these features and is used for predicting against the new text.</p>

<ul>
  <li>
    <p>Durchgängigkeit zu anderen Spark ML Algorithmen</p>
  </li>
  <li>
    <p>NaiveBayes Classifier</p>
  </li>
</ul>

<p>++ Vectorize text documents for use with other ML libraries, but:: start with text (sentences, …)</p>

<p>+++ TF-IDF Vectors (überprüfen)</p>

<p>The text classification model are heavily dependent upon the quality and quantity of features, while applying any machine learning model it is always a good practice to include more and more training data. H ere are some tips that I wrote about improving the text classification accuracy in one of my previous article.</p>

<p>4.2 Text Matching / Similarity
One of the important areas of NLP is the matching of text objects to find similarities. Important applications of text matching includes automatic spelling correction, data de-duplication and genome analysis etc.</p>

<p>A number of text matching techniques are available depending upon the requirement. This section describes the important techniques in detail.</p>

<p>A. Levenshtein Distance – The Levenshtein distance between two strings is defined as the minimum number of edits needed to transform one string into the other, with the allowable edit operations being insertion, deletion, or substitution of a single character. Following is the implementation for efficient memory computations.</p>

<p>B. Phonetic Matching – A Phonetic matching algorithm takes a keyword as input (person’s name, location name etc) and produces a character string that identifies a set of words that are (roughly) phonetically similar. It is very useful for searching large text corpuses, correcting spelling errors and matching relevant names. Soundex and Metaphone are two main phonetic algorithms used for this purpose. Python’s module Fuzzy is used to compute soundex strings for different words, for example –</p>

<p>C. Flexible String Matching – A complete text matching system includes different algorithms pipelined together to compute variety of text variations. Regular expressions are really helpful for this purposes as well. Another common techniques include – exact string matching, lemmatized matching, and compact matching (takes care of spaces, punctuation’s, slangs etc).</p>

<p>D. Cosine Similarity – W hen the text is represented as vector notation, a general cosine similarity can also be applied in order to measure vectorized similarity. Following code converts a text to vectors (using term frequency) and applies cosine similarity to provide closeness among two text.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import math
from collections import Counter
def get_cosine(vec1, vec2):
    common = set(vec1.keys()) &amp; set(vec2.keys())
    numerator = sum([vec1[x] * vec2[x] for x in common])

    sum1 = sum([vec1[x]**2 for x in vec1.keys()])
    sum2 = sum([vec2[x]**2 for x in vec2.keys()])
    denominator = math.sqrt(sum1) * math.sqrt(sum2)

    if not denominator:
        return 0.0
    else:
        return float(numerator) / denominator

def text_to_vector(text):
    words = text.split()
    return Counter(words)

text1 = 'This is an article on analytics vidhya'
text2 = 'article on analytics vidhya is about natural language processing'

vector1 = text_to_vector(text1)
vector2 = text_to_vector(text2)
cosine = get_cosine(vector1, vector2)
&gt;&gt;&gt; 0.62
</code></pre></div></div>
<p>4.3 Coreference Resolution
Coreference Resolution is a process of finding relational links among the words (or phrases) within the sentences. Consider an example sentence: ” Donald went to John’s office to see the new table. He looked at it for an hour.“</p>

<p>Humans can quickly figure out that “he” denotes Donald (and not John), and that “it” denotes the table (and not John’s office). Coreference Resolution is the component of NLP that does this job automatically. It is used in document summarization, question answering, and information extraction. Stanford CoreNLP provides a python wrapper for commercial purposes.</p>

<p>4.4 Other NLP problems / tasks
Text Summarization – Given a text article or paragraph, summarize it automatically to produce most important and relevant sentences in order.
Machine Translation – Automatically translate text from one human language to another by taking care of grammar, semantics and information about the real world, etc.
Natural Language Generation and Understanding – Convert information from computer databases or semantic intents into readable human language is called language generation. Converting chunks of text into more logical structures that are easier for computer programs to manipulate is called language understanding.
Optical Character Recognition – Given an image representing printed text, determine the corresponding text.
Document to Information – This involves parsing of textual data present in documents (websites, files, pdfs and images) to analyzable and clean format.</p>

<ul>
  <li>Downgraded to Apache Spark v2.1.3</li>
</ul>

<h2 id="spark-nlp">Spark-NLP</h2>

<p>The John Snow Labs NLP Library, Spark-NLP, natively extends the Spark ML API.</p>

<ol>
  <li>What is Spark NLP?
Spark NLP is an open-source natural language processing library, built on top of Apache Spark and Spark ML. It provides an easy API to integrate with ML Pipelines and it is commercially supported by John Snow Labs. Spark NLP’s annotators utilize rule-based algorithms, machine learning and some of them Tensorflow running under the hood to power specific deep learning implementations.
The library covers many common NLP tasks, including tokenization, stemming, lemmatization, part of speech tagging, sentiment analysis, spell checking, named entity recognition, and more. The full list of annotators, pipelines, and concepts is described in the online reference. All of them are included as open-source and can be used by training models with your data. It also provides pre-trained pipelines and models, although they serve as a way of getting a feeling on how the library works, and not for production use.
Spark NLP library is written in Scala and it includes Scala and Python APIs for use from Spark. It has no dependency on any other NLP or ML library. For each type of annotator, we do an academic literature review to find the state of the art (SOTA), have a team discussion and decide which algorithm(s) to implement. Implementations are evaluated on three criteria:
Accuracy — there’s no point in a great framework if it has sub-par algorithms or models.
Performance — runtime should be on par or better than any public benchmark. No one should have to give up accuracy because annotators don’t run fast enough to handle a streaming use case, or don’t scale well in a cluster setting.
Trainability or Configurability — NLP is an inherently domain-specific problem. Different grammars and vocabularies are used in social media posts vs. academic papers vs. electronic medical records vs. newspaper articles.
Spark NLP is geared towards production use in software systems that outgrow older libraries such as spaCy, NLTK, and CoreNLP. As of February 2019, the library is in use by 16% of enterprise companies and the most widely used NLP library by such companies.
Built natively on Apache Spark and TensorFlow, the library provides simple, performant as well as accurate NLP notations for machine learning pipelines which can scale easily in a distributed environment. This library is reusing the Spark ML pipeline along with integrating NLP functionality.
In a recent annual survey by O’Reilly, it identified several trends among enterprise companies for adopting artificial intelligence. According to the survey results, Spark NLP library was listed as the seventh most popular across all AI frameworks and tools. It is also by far the most widely used NLP library — twice as common as spaCy. It was also found to be the most popular AI library after scikit-learn, TensorFlow, Keras, and PyTorch.</li>
</ol>

<h2 id="why-spark-nlp">Why Spark-NLP?</h2>

            </div>
          </div>
        </div>
        <div class="column-right"></div>
      </div>

      
<div class="site-footer">

    <div class="column-left"></div>
    <div class="column-content">
      Predictive<span class="brand-teal">Works.</span> is an initiative of Dr. Krusche & Partner PartG - (c) 2020. All rights reserved.
    </div>
    <div class="column-right"></div>

</div>


  </body>
</html>
